{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"新聞分類預測.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"i5doOG9iIsYg","colab_type":"text"},"source":["##雲端硬碟設定指向"]},{"cell_type":"code","metadata":{"id":"8CqfyK8SIo2o","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1595169083771,"user_tz":-480,"elapsed":16336,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}},"outputId":"7c913d25-f0c5-4e15-d4c6-1e790cd51423"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"72Pg2ymcGyg2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595169085506,"user_tz":-480,"elapsed":18060,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}},"outputId":"31cfeaf8-d1bc-4ef5-c7fc-4a913b18af2f"},"source":["!ls 'drive'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["'My Drive'  'Shared drives'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2537ws1rGzz8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169085757,"user_tz":-480,"elapsed":18307,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["import os\n","path = \"/content/drive/My Drive/Colab Notebooks/Bert/AML/\"\n","os.chdir(path)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"KdtNtU4DG02O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1595169087633,"user_tz":-480,"elapsed":20176,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}},"outputId":"2dc5b6e6-38d4-49b2-f6e8-76e9d5051ff6"},"source":["!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":[" albert      trained_model4\t\t\t '名字分類(變成姓名學了).ipynb'\n"," data\t     trained_model5\t\t\t '名字預測(變成姓名學了).ipynb'\n"," data.zip    使用word2vec结合Textrank模型.ipynb   新聞分類訓練.ipynb\n"," NER.ipynb   分類250.ipynb\t\t\t  新聞分類預測.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zTTRKGWmGwIi","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169087634,"user_tz":-480,"elapsed":20173,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["import os\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"izrwwtHWIq2y","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169090617,"user_tz":-480,"elapsed":23153,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["import torch\n","from torch.utils.data import TensorDataset\n","import pickle"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"qI2eEjYlIq21","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"ok","timestamp":1595169090621,"user_tz":-480,"elapsed":23150,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}},"outputId":"029d2c2f-8390-4d69-c582-1d55faf4e51c"},"source":["import sys \n","sys.path.append('.')\n","sys.path"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['',\n"," '/env/python',\n"," '/usr/lib/python36.zip',\n"," '/usr/lib/python3.6',\n"," '/usr/lib/python3.6/lib-dynload',\n"," '/usr/local/lib/python3.6/dist-packages',\n"," '/usr/lib/python3/dist-packages',\n"," '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n"," '/root/.ipython',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"R690qw7_Iq28","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169090621,"user_tz":-480,"elapsed":23146,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["def use_model(model_name, config_file_path, model_file_path, vocab_file_path, num_labels):\n","    # 選擇模型並加載設定\n","    if(model_name == 'bert'):\n","        from transformers import BertConfig, BertForSequenceClassification, BertTokenizer\n","        model_config, model_class, model_tokenizer = (BertConfig, BertForSequenceClassification, BertTokenizer)\n","        config = model_config.from_pretrained(config_file_path,num_labels = num_labels)\n","        model = model_class.from_pretrained(model_file_path, from_tf=bool('.ckpt' in 'bert-base-chinese'), config=config)\n","        tokenizer = model_tokenizer(vocab_file=vocab_file_path)\n","        return model, tokenizer\n","    elif(model_name == 'albert'):\n","        from albert.albert_zh import AlbertConfig, AlbertTokenizer, AlbertForSequenceClassification\n","        model_config, model_class, model_tokenizer = (AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer)\n","        config = model_config.from_pretrained(config_file_path,num_labels = num_labels)\n","        model = model_class.from_pretrained(model_file_path, config=config)\n","        tokenizer = model_tokenizer.from_pretrained(vocab_file_path)\n","        return model, tokenizer"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hDB85MctCh2L","colab_type":"text"},"source":["## 定義函式-快速建立BERT INPUT( tokenizer.build_inputs_with_special_tokens() )"]},{"cell_type":"code","metadata":{"id":"MmJzMkGVIq3B","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169090622,"user_tz":-480,"elapsed":23144,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["def to_bert_ids(tokenizer,q_input):\n","    # 將文字輸入轉換成對應的id編號\n","    #快速建立BERT INPUT\n","    return tokenizer.build_inputs_with_special_tokens(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(q_input)))"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"874XML3eIq3K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169090622,"user_tz":-480,"elapsed":23141,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["class DataDic(object):\n","    def __init__(self, answers):\n","        self.answers = answers #全部答案(含重複)\n","        self.answers_norepeat = sorted(list(set(answers))) # 不重複\n","        self.answers_types = len(self.answers_norepeat) # 總共多少類\n","        self.ans_list = [] # 用於查找id或是text的list\n","        self._make_dic() # 製作字典\n","    \n","    def _make_dic(self):\n","        for index_a,a in enumerate(self.answers_norepeat):\n","            if a != None:\n","                self.ans_list.append((index_a,a))\n","\n","    def to_id(self,text):\n","        for ans_id,ans_text in self.ans_list:\n","            if text == ans_text:\n","                return ans_id\n","\n","    def to_text(self,id):\n","        for ans_id,ans_text in self.ans_list:\n","            if id == ans_id:\n","                return ans_text\n","\n","    @property\n","    def types(self):\n","        return self.answers_types\n","    \n","    @property\n","    def data(self):\n","        return self.answers\n","\n","    def __len__(self):\n","        return len(self.answers)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tycap9n9Iq3Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169090623,"user_tz":-480,"elapsed":23140,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["from torch.utils.data import DataLoader\n","import torch"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"ASRta1EgZ5Yi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":185},"executionInfo":{"status":"ok","timestamp":1595169103238,"user_tz":-480,"elapsed":35752,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}},"outputId":"2081a227-3fcd-4a0e-80b6-e16a10b77baa"},"source":["! pip install snownlp"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Collecting snownlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/b3/37567686662100d3bce62d3b0f2adec18ab4b9ff2b61abd7a61c39343c1d/snownlp-0.12.3.tar.gz (37.6MB)\n","\u001b[K     |████████████████████████████████| 37.6MB 81kB/s \n","\u001b[?25hBuilding wheels for collected packages: snownlp\n","  Building wheel for snownlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for snownlp: filename=snownlp-0.12.3-cp36-none-any.whl size=37760958 sha256=a94f48127a04a64db8400baa11e264008f53cc66bad4d0929e84b3aa84c6fb92\n","  Stored in directory: /root/.cache/pip/wheels/f3/81/25/7c197493bd7daf177016f1a951c5c3a53b1c7e9339fd11ec8f\n","Successfully built snownlp\n","Installing collected packages: snownlp\n","Successfully installed snownlp-0.12.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W-z6kgTzZ7cL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169105817,"user_tz":-480,"elapsed":38329,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["from snownlp import SnowNLP"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWea7sbTsz6r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595169182597,"user_tz":-480,"elapsed":115101,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}},"outputId":"c87e8d78-e664-430b-f571-24f74dee7c33"},"source":["!pip install -U ckiptagger[tfgpu,gdown]"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Collecting ckiptagger[gdown,tfgpu]\n","  Downloading https://files.pythonhosted.org/packages/5d/24/9ee7289b423345bc1705453437d9b0d9e93a015fbc00885c6033c2f50fab/ckiptagger-0.1.1-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: gdown; extra == \"gdown\" in /usr/local/lib/python3.6/dist-packages (from ckiptagger[gdown,tfgpu]) (3.6.4)\n","Collecting tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/ab/19aba3629427c2d96790f73838639136ce02b6e7e1c4f2dd60149174c794/tensorflow_gpu-1.15.3-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n","\u001b[K     |████████████████████████████████| 411.0MB 41kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (2.23.0)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (4.41.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (1.12.0)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.9.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 39.1MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.34.2)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 50.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (3.2.1)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.1.2)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.2.0)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.1.0)\n","Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.12.1)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.0.8)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (0.8.1)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.30.0)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (3.12.2)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.18.5)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown; extra == \"gdown\"->ckiptagger[gdown,tfgpu]) (1.24.3)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (49.1.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (3.2.2)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.0.1)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (2.10.0)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (1.7.0)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu<2,>=1.13.1; extra == \"tfgpu\"->ckiptagger[gdown,tfgpu]) (3.1.0)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=14fb56bceec0d99ac03138294680ad3c3f7ef08559160a7ed7015d410ebea6b3\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.2.0 has requirement tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: tensorboard, tensorflow-estimator, gast, tensorflow-gpu, ckiptagger\n","  Found existing installation: tensorboard 2.2.2\n","    Uninstalling tensorboard-2.2.2:\n","      Successfully uninstalled tensorboard-2.2.2\n","  Found existing installation: tensorflow-estimator 2.2.0\n","    Uninstalling tensorflow-estimator-2.2.0:\n","      Successfully uninstalled tensorflow-estimator-2.2.0\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","Successfully installed ckiptagger-0.1.1 gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wn25ypQ5s0mB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169184061,"user_tz":-480,"elapsed":116562,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["from ckiptagger import data_utils, construct_dictionary, WS, POS, NER"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXVT_uFUs3Rq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169184063,"user_tz":-480,"elapsed":116562,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["def load_data():\n","    # 使用 GPU：\n","    #    1. 安裝 tensorflow-gpu (請見安裝說明)\n","    #    2. 設定 CUDA_VISIBLE_DEVICES 環境變數，例如：os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","    #    3. 設定 disable_cuda=False，例如：ws = WS(\"./data\", disable_cuda=False)\n","    # 使用 CPU：\n","    global ws, pos,ner\n","    ws = WS(\"./data\", disable_cuda=False)\n","    pos = POS(\"./data\", disable_cuda=False)\n","    ner = NER(\"./data\", disable_cuda=False)\n","\n","def get_person_str(context):\n","  \n","    load_data()\n","\n","    sentence_list = [context]\n","\n","    word_sentence_list = ws(\n","        sentence_list,\n","        # sentence_segmentation = True, # To consider delimiters\n","        # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}), # This is the defualt set of delimiters\n","        # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n","        # coerce_dictionary = dictionary2, # words in this dictionary are forced\n","    )\n","\n","    pos_sentence_list = pos(word_sentence_list)\n","    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n","    #print(entity_sentence_list)\n","\n","    set_entity=set()    \n","    for i, sentence in enumerate(sentence_list):\n","        #print()\n","        #print(f\"'{sentence}'\")\n","        #print_word_pos_sentence(word_sentence_list[i],  pos_sentence_list[i])\n","        for entity in sorted(entity_sentence_list[i]):\n","              if entity[2] == 'PERSON':\n","                #print(entity[3])\n","                set_entity.add(entity[3].replace(\" \", \"\"))\n","    str_entity = ','.join(set_entity)\n","    #print(str_entity)\n","    return str_entity.split(\",\")"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Ybk7xbkh5aM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595169185064,"user_tz":-480,"elapsed":117561,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}}},"source":["# load and init\n","pkl_file = open('trained_model5/data_features.pkl', 'rb')\n","data_features = pickle.load(pkl_file)\n","answer_dic = data_features['answer_dic']"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q7NOoJkpiCGL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1595170010263,"user_tz":-480,"elapsed":146815,"user":{"displayName":"張仲威","photoUrl":"","userId":"14727305247088321457"}},"outputId":"c705f944-f0bd-46ca-be32-4b0c8d34ecdf"},"source":["model_setting2 = {\n","    \"model_name\":\"albert\", \n","    \"config_file_path\":\"trained_model5/config.json\", \n","    \"model_file_path\":\"trained_model5/pytorch_model.bin\", \n","    \"vocab_file_path\":\"albert/albert_tiny/vocab.txt\",\n","    \"num_labels\":2 # 分幾類\n","}    \n","model, tokenizer = use_model(**model_setting2)\n","model.eval()\n","\n","#\n","q_inputs = [u'高雄近日爆發「直播主之亂」 ，知名直播主連千毅與寵物店老闆兼直播主鄭又仁槓上，引發砸店、開槍風波，昨日雙雙落網，今早分別進行偵訊。如今傳出連千毅直播販售的「賓士行李箱」疑為假貨，高雄檢警20日前往倉庫搜索將證物帶回，連千毅連忙開直播澄清，強調自己是代銷商，更秀出簡體字授權函，強調絕對是正品，但卻遭台灣賓士打臉，直指「德國奔馳戴姆勒公司」不存在！▲連千毅如今傳出賣假貨疑雲。（圖／翻攝臉書）連千毅又被封為「直播天王」，短短幾分鐘就能賣出跑車、直升機等，成功在業界闖出一片天，多次登上媒體版面，但卻因行事作風太高調，引來黑道注目，不僅衝突頻傳，如今更傳出他所賣的「賓士行李箱」是假貨。高雄檢警20日上午會同保二總隊、經發局等單位，聯合稽查搜索連千毅的倉庫直播站，當場查扣一些賓士行李箱等商品，疑似有仿冒嫌疑，將其帶回調查，連千毅則大動作維護商譽，強調自己是代銷商，「全亞洲不是只有你賣賓士！」、「今天台灣授權廠商有講，未經他們認同的都非正貨，路上10台有8台是水貨車，你能說他是山寨仿冒嗎？」並揚言要對不實媒體提告。▲連千毅強調自己只是代銷商。（圖／翻攝臉書）連千毅秀出賓士授權函，強調產品是正品，但卻有眼尖網友發現疑點，除了中文部分皆用簡體字外，連授權書的英文都拼錯，將「AUTHORIZATION」打成「AUTHORIZAT『T』ON」，此外授權方「茲」也不知道是誰，台灣賓士對此回應：「我們戴姆勒集團旗下子公司，沒有一個叫做『德國奔馳戴姆勒公司』，並沒有這樣的公司存在。」據《ETtoday》報導，追查同款式行李箱，發現連千毅在直播上喊價拍賣上，知名購物平台也有同款商品，要價3萬9千元，但連千毅卻從6000元開始喊價，價差相當之大，如今傳出該款行李箱為仿冒品後，商品已從該網站悄悄下架， 避免衍生風波。']\n","\n","for q_input in q_inputs:\n","    old_q_input=q_input\n","    if len(tokenizer.tokenize(q_input)) >511 :\n","      q_input=q_input[0:510]\n","    bert_ids = to_bert_ids(tokenizer,q_input)\n","    print('len(bert_ids)',len(bert_ids))\n","    assert len(bert_ids) <= 512\n","    input_ids = torch.LongTensor(bert_ids).unsqueeze(0)\n","\n","    # predict\n","    outputs = model(input_ids)\n","    predicts = outputs[:2]\n","    predicts = predicts[0]\n","    max_val = torch.max(predicts)\n","    label = (predicts == max_val).nonzero().numpy()[0][1]\n","    ans_label = answer_dic.to_text(label)\n","    \n","    print(q_input)\n","    print(ans_label)\n","    if ans_label =='0':\n","        print('[]');\n","    else:\n","        snow_nlp = SnowNLP(old_q_input)\n","        snow_summer_list=snow_nlp.summary(10)\n","        snow_summer_str = \",\".join(snow_summer_list)\n","        print(get_person_str(snow_summer_str)) #['馬勝', '安東尼羅賓', '廖泰宇']"],"execution_count":21,"outputs":[{"output_type":"stream","text":["len(bert_ids) 487\n","前新北市副市長許志堅2015年因收受建商賄賂 ，幫助建商快速通過都更案，今年3月判刑10年定讞並入監執行。板橋區介壽段與新店區廣明段2筆都更案在他涉賄案發後，市府皆暫停審議程序，至今停擺3年餘。依法院判決結果，許志堅違反貪污治罪條例不違背職務收受賄賂罪，今年7月初市府都市更新處發文給申請人，通知案件可繼續審議。板橋區介壽段都更案位於中山路1段、中山路1段50巷與民族路街廓，距捷運府中站300公尺，鄰近熱鬧的府中商圈，基地面積約1275平方公尺，其中市有地面積1266平方公尺，公有地佔整體比率99％，土地使用分區為商業區，預計興建地上19層大樓。2013年財政局辦理公開甄選作業，由樂揚建設取得最優申請人資格。請繼續往下閱讀...新店廣明段都更案位於新店區北宜路1段、能仁路口，鄰近新店國小，基地面積5951平方公尺，距捷運新店站600公尺，土地使用分區為住宅區，範圍內多為老舊磚造或鐵皮屋等建物，巷道狹小，寶興建設2008年起申請都更，預計興建地上29層大樓。都市更新處主任秘書李擇仁表示，當初2案進入司法調查階段，因此暫停審議程序，依據高等法院判決結果，許志堅違反貪污治罪條例不違背職務收賄罪，意為行賄事實與案件\n","1\n","['許志堅']\n"],"name":"stdout"}]}]}